{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390bfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import nltk\n",
    "import stanza\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "#stanza.download('en')\n",
    "#nltk.download('brown')\n",
    "#nltk.download('punkt')\n",
    "comprehend = boto3.client(service_name='comprehend',\n",
    "                          region_name='us-east-1',\n",
    "                          aws_access_key_id='AKIAWFPZMNZHUGEYWIIS',\n",
    "                          aws_secret_access_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0771679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 09:55:37 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-03-28 09:55:37 INFO: Use device: cpu\n",
      "2022-03-28 09:55:37 INFO: Loading: tokenize\n",
      "2022-03-28 09:55:37 INFO: Loading: pos\n",
      "2022-03-28 09:55:37 INFO: Loading: lemma\n",
      "2022-03-28 09:55:37 INFO: Loading: depparse\n",
      "2022-03-28 09:55:37 INFO: Loading: sentiment\n",
      "2022-03-28 09:55:38 INFO: Loading: constituency\n",
      "2022-03-28 09:55:38 INFO: Loading: ner\n",
      "2022-03-28 09:55:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53105551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = cleanhtml(sentence)\n",
    "    \n",
    "    sentiment = json.dumps(comprehend.detect_sentiment(Text=sentence, LanguageCode='en'),\n",
    "                           sort_keys=True,\n",
    "                           indent=4)\n",
    "    sentiment = json.loads(sentiment)['Sentiment']\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0ebde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asp(sentence):\n",
    "    important = nlp(sentence)\n",
    "    target = ''\n",
    "    for sent in important.sentences:\n",
    "        for wrd in sent.words:\n",
    "            if wrd.deprel == 'nsubj' and wrd.pos == 'NOUN':\n",
    "                target = wrd.text\n",
    "    return target\n",
    "\n",
    "def get_desp(sentence):\n",
    "    important = nlp(sentence)\n",
    "    descriptive_item = ''\n",
    "    added_terms = ''\n",
    "    for sent in important.sentences:\n",
    "        for wrd in sent.words:\n",
    "            if wrd.pos == 'ADV' and wrd.deprel == 'advmod':\n",
    "                added_terms = wrd.text\n",
    "            if wrd.pos == 'ADJ':\n",
    "                descriptive_item = added_terms + ' ' + wrd.text\n",
    "    return descriptive_item\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1d16b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cc3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_phrases(sentence):\n",
    "    # html cleaning\n",
    "    sentence = str(sentence)\n",
    "    sentence = cleanhtml(sentence)\n",
    "    noun_phrases = TextBlob(sentence).noun_phrases\n",
    "    noun_phrases = (','.join(map(str, noun_phrases)))\n",
    "    \n",
    "    if(len(noun_phrases) <= 1):  \n",
    "        aspect = get_asp(sentence)\n",
    "        descriptive_item = get_desp(sentence)\n",
    "        aspect_descp = descriptive_item +' ' +aspect\n",
    "        noun_phrases = aspect_descp\n",
    "    else:\n",
    "        noun_phrases = noun_phrases\n",
    "    return noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b7b925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'india'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_noun_phrases('I loves India.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5cff2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working batch prediction code for more than 25 sentences\n",
    "def get_batch_sentiment(sentence_list):\n",
    "    sentiments_list=[]\n",
    "    n = 25\n",
    "    chunks_list = [sentence_list[i * n:(i + 1) * n] for i in range((len(sentence_list) + n - 1) // n )]\n",
    "    for i in range(len(chunks_list)):\n",
    "      batch_sentiment = json.dumps(comprehend.batch_detect_sentiment(TextList=chunks_list[i], LanguageCode='en'),sort_keys=True,indent=4)\n",
    "      batch_sentiment = json.loads(batch_sentiment)\n",
    "    \n",
    "      for i in range(len(batch_sentiment['ResultList'])):\n",
    "          sentiment = batch_sentiment['ResultList'][i]['Sentiment']\n",
    "          sentiments_list.append(sentiment)\n",
    "          \n",
    "    return sentiments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "235a538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list =['I love India','I hate India','I neutral India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6880db1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE', 'NEUTRAL']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_sentiment(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1e2e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_noun(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = cleanhtml(sentence)\n",
    "    \n",
    "    sentiment = json.dumps(comprehend.detect_sentiment(Text=sentence, LanguageCode='en'),\n",
    "                           sort_keys=True,\n",
    "                           indent=4)\n",
    "    sentiment = json.loads(sentiment)['Sentiment']\n",
    "    noun_phrases = TextBlob(sentence).noun_phrases\n",
    "    noun_phrases = (','.join(map(str, noun_phrases)))\n",
    "    \n",
    "    if(len(noun_phrases) <= 1):  \n",
    "        aspect = get_asp(sentence)\n",
    "        descriptive_item = get_desp(sentence)\n",
    "        aspect_descp = descriptive_item +' ' +aspect\n",
    "        noun_phrases = aspect_descp\n",
    "    else:\n",
    "        noun_phrases = noun_phrases\n",
    "\n",
    "    output = {'sentence': sentence,'sentiment': sentiment, 'noun_phrases': noun_phrases}    \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37358958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'This is Aamir and I am Happy',\n",
       " 'sentiment': 'POSITIVE',\n",
       " 'noun_phrases': 'aamir,happy'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_noun(\"This is Aamir and I am Happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad85ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun phrases when sent a list\n",
    "\n",
    "def get_noun_phrases(sentence_list):\n",
    "    noun_phrases_list = []\n",
    "    for i in range(len(sentence_list)):\n",
    "      # html cleaning\n",
    "      sentence = str(sentence_list[i])\n",
    "      sentence = cleanhtml(sentence)\n",
    "      noun_phrases = TextBlob(sentence).noun_phrases\n",
    "      noun_phrases = (','.join(map(str, noun_phrases)))\n",
    "    \n",
    "      if(len(noun_phrases) <= 1):  \n",
    "          aspect = get_asp(sentence)\n",
    "          descriptive_item = get_desp(sentence)\n",
    "          aspect_descp = descriptive_item +' ' +aspect\n",
    "          noun_phrases = aspect_descp\n",
    "      else:\n",
    "          noun_phrases = noun_phrases\n",
    "      noun_phrases_list.append(noun_phrases)\n",
    "    \n",
    "    return noun_phrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412b9946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india', 'india', 'india']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_noun_phrases(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc997d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list =['I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore','I love India','I am Aamir and I love India','Aamir lives in Bangalore']\n",
    "\n",
    "sentiments = get_batch_sentiment(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af04cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac610dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9dbdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
